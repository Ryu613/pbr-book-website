
<!doctype html>
<html lang="en">
<head>

<!-- all praise to https://realfavicongenerator.net -->
<link rel="icon" href="/favicon.ico?v=2" /> <!-- force refresh -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="/fonts.css">
  <link rel="stylesheet" href="../pbrstyle.css">
  <link rel="stylesheet" href="/fontawesome-free-5.15.3-web/css/all.css">

<script async src="https://cse.google.com/cse.js?cx=22a43cef261a245ea"></script>  <script src="/react.min.js"></script>
  <script src="/react-dom.min.js"></script>
  <script src="/jeri.min.js"></script>
  <link rel="preload" href="/exr.worker.js" as="script" crossorigin="anonymous">
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="/bootstrap.min.css">

  <title>Further Reading</title>
</head>
        
<body>

<nav class="fixed-top-lg-navbar navbar navbar-expand bg-light navbar-light">
  <ul class="nav navbar-nav">
    <a class="navbar-brand" href="../contents.html"><img src="../pbr.jpg" width=25 height=25></a>
    <li class="nav-item"><a class="nav-link" href="../Light_Sources.html">Light Sources</a></li>
    <span class="navbar-text">/</span>
    <li class="nav-item"><a class="nav-link" href="#">Further Reading</a></li>
    <span class="navbar-text">&nbsp;&nbsp;</span>
    <li class="nav-item"><a class="nav-link" href="../Light_Sources/Light_Sampling.html">(Previous: Light Sampling)</a></li>
  </ul>

  <ul class="nav navbar-nav ml-auto d-none d-md-block">
        <li class="nav-item"><div class="gcse-search"></div></li>
    </ul>
  <ul class="nav navbar-nav d-block d-md-none">
        <li class="nav-item"><div class="gcse-search"></div></li>
    </ul>
</nav>

<div class="maincontainer">
<div class="container-fluid">

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">

</div>
<div class="col-md-10 col-lg-8">

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#"><i class="fas fa-link "></i></a>
</div>
<div class="col-md-10 col-lg-8">
<h2>Further Reading</h2><p>


</p>
<p>

</p>
<p></p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#x3-LightEmissionDescriptions"><i class="fas fa-link h3h4marginlink"></i></a>
</div>
<div class="col-md-10 col-lg-8">
<span id="x3-LightEmissionDescriptions"></span><h4>Light Emission Descriptions</h4><p>


</p>
<p>Warn (<a href="#cite:Warn83">1983</a>) developed early models of light sources with
nonisotropic emission distributions, including the spotlight model used in
this chapter.  Verbeck and Greenberg (<a href="#cite:Verbeck:1984:ACL">1984</a>) also
described a number of techniques for modeling light sources that are now
classic parts of the light modeling toolbox.  Barzel (<a href="#cite:Barzel97">1997</a>)
described a highly parameterized model for light sources, including multiple
parameters for controlling rate of falloff, the area of space that is
illuminated, and so on.  Bjorke (<a href="#cite:Bjorke01">2001</a>) described a number of
additional techniques for shaping illumination for artistic effect.
(Many parts of the Barzel and Bjorke approaches are not physically based,
however.)

</p>
<p>The goniophotometric light source approximation is widely used to model area
light sources in the field of illumination engineering.  The rule of thumb
there is that once a reference point is five times an area light source&rsquo;s
radius away from it, a point light approximation has sufficient accuracy
for most applications.  File format standards have been developed for
encoding goniophotometric diagrams for these applications (Illuminating
Engineering Society of North America&nbsp;<a href="#cite:IESNA2002">2002</a>). Many lighting
fixture manufacturers provide data in these formats on their websites.

</p>
<p>Ashdown (<a href="#cite:Ashdown:1993:NPA">1993</a>) proposed a more sophisticated light
source model than goniophotometric; he measured the directional
distribution of emitted radiance at a large number of points around a light
source and described how to use the resulting 4D table to compute the
received radiance distribution at other points.  Another generalization of
goniometric lights was suggested by Heidrich
et&nbsp;al. (<a href="#cite:Heidrich98a">1998</a>), who represented light sources as a 4D
exitant <em>lightfield</em>&mdash;essentially a function of both position and
direction&mdash;and showed how to use this representation for rendering.
Additional work in this area was done by Goesele
et&nbsp;al. (<a href="#cite:Goesele2003">2003</a>) and Mas et&nbsp;al. (<a href="#cite:Mas2008">2008</a>), who
introduced a more space-efficient representation and improved rendering
efficiency.

</p>
<p>Peters (<a href="#cite:Peters2021linear">2021a</a>) has developed efficient techniques for
sampling lights defined by lines (i.e., infinitesimally thin cylinders)
and shown how to sample the product of lighting and the BRDF using linearly
transformed cosines (<a href="#cite:Heitz2016">Heitz et al. 2016a</a>).

</p>
<p>Real-world light sources are often fairly complex, including carefully
designed systems of mirrors and lenses to shape the distribution of light
emitted by the light source.  (Consider, for example, the headlights on a
car, where it is important to evenly illuminate the surface of the road
without shining too much light in the eyes of approaching drivers.)

All the corresponding specular
reflection and transmission is challenging for light transport
algorithms.


It can therefore be worthwhile to do some precomputation to
create a representation of light sources&rsquo; final emission distributions
after all of this scattering that is then used as the light source model
for rendering.  To this end, Kniep et&nbsp;al. (<a href="#cite:Kniep2009">2009</a>) proposed
tracing the paths of photons leaving the light&rsquo;s filament until they hit a
bounding surface around the light. They then recorded the position and
direction of outgoing photons and used this information when computing
illumination at points in the scene.  Vel&aacute;zquez-Armend&aacute;riz
et&nbsp;al. (<a href="#cite:Velazquez-Armendariz2015">2015</a>) showed how to compute a set of
point lights with directionally varying emission distributions to model
emitted radiance from complex light sources.  They then approximated the
radiance distribution in the light interior using spherical harmonics.
More recently, Zhu et al. (<a href="#cite:Zhu2021:luminaires">2021</a>) applied a neural
representation to complex lights, encoding lights&rsquo; radiance distributions
and view-dependent sampling distributions and opacities in neural networks.

</p>
<p>

</p>
<p></p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#x3-IlluminationfromEnvironmentMaps"><i class="fas fa-link h3h4marginlink"></i></a>
</div>
<div class="col-md-10 col-lg-8">
<span id="x3-IlluminationfromEnvironmentMaps"></span><h4>Illumination from Environment Maps</h4><p>


</p>
<p>Blinn and Newell (<a href="#cite:Blinn76">1976</a>) first introduced the idea of
environment maps and their use for simulating illumination, although they
only considered illumination of specular objects.  Greene
(<a href="#cite:Greene86b">1986</a>) further refined these ideas, considering
antialiasing and different representations for environment maps.  Nishita
and Nakamae (<a href="#cite:Nishita:1986:CTR">1986</a>) developed algorithms for
efficiently rendering objects illuminated by hemispherical skylights and
generated some of the first images that showed off that distinctive
lighting effect.  Miller and Hoffman (<a href="#cite:Miller84">1984</a>) were the first
to consider using arbitrary environment maps to illuminate objects with
diffuse and glossy BRDFs.  Debevec (<a href="#cite:Debevec98">1998</a>) later extended
this work and investigated issues related to capturing images of real
environments.

</p>
<p>Representing illumination from the sun and sky is a particularly important
application of infinite light sources; the &ldquo;Further Reading&rdquo; section in
Chapter&nbsp;<a href="../Light_Transport_II_Volume_Rendering.html#chap:volume-integration">14</a> includes a number of references
related to simulating skylight scattering.  Directly measuring illumination
from the sky is also an effective way to find accurate skylight
illumination; see Kider et&nbsp;al. (<a href="#cite:Kider2014">2014</a>) for details of a
system built to do this.

</p>
<p><tt>pbrt</tt>&rsquo;s infinite area light source models incident radiance from the light
as purely a function of direction.  Especially for indoor scenes, this
assumption can be fairly inaccurate; position matters as well.  Unger
et&nbsp;al. (<a href="#cite:Unger2003">2003</a>) captured the incident radiance as a function
of direction at many different locations in a real-world scene and used
this representation for rendering.  Unger et&nbsp;al. (<a href="#cite:Unger2008">2008</a>)
improved on this work and showed how to decimate the samples to reduce
storage requirements without introducing too much error.  Lu
et&nbsp;al. (<a href="#cite:Lu2015">2015</a>) developed techniques for efficiently importance
sampling these light sources.

</p>
<p>The use of the <tt>allowIncompletePDF</tt> parameter to avoid generating
low-probability samples from infinite light sources in the presence of
multiple importance sampling is an application of MIS compensation, which
was developed by Karl&iacute;k et&nbsp;al. (<a href="#cite:Karlik2019">2019</a>).

</p>
<p>Subr and Arvo (<a href="#cite:Subr07b">2007b</a>) developed an efficient technique for sampling
environment map light sources that not only accounts for the <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.589ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 1975.7 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">cosine theta</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-LATINMODERNMAIN-63" d="M415 119c0 -10 -32 -130 -166 -130c-116 0 -215 99 -215 227c0 124 92 232 217 232c77 0 153 -39 153 -107c0 -30 -20 -47 -46 -47c-28 0 -46 20 -46 46c0 13 6 43 47 46c-35 36 -98 37 -107 37c-53 0 -135 -42 -135 -205c0 -161 88 -204 141 -204c37 0 102 12 131 105 c2 6 4 10 13 10c3 0 13 0 13 -10Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-6F" d="M471 214c0 -127 -101 -225 -222 -225c-117 0 -221 96 -221 225c0 125 97 234 222 234c121 0 221 -106 221 -234zM388 222c0 38 0 96 -26 139s-69 65 -113 65c-40 0 -87 -21 -114 -67c-24 -44 -24 -98 -24 -137c0 -36 0 -97 25 -141c27 -46 71 -67 114 -67 c50 0 94 29 116 74c22 44 22 98 22 134Z"></path>
<path stroke-width="1" id="E1-LATINMODERNMAIN-73" d="M360 128c0 -72 -46 -139 -161 -139c-21 0 -66 1 -110 43c-18 -19 -18 -21 -20 -23c-19 -19 -20 -20 -25 -20c-11 0 -11 7 -11 24v132c0 18 0 25 13 25c10 0 11 -4 14 -17c19 -85 55 -142 139 -142c78 0 113 40 113 91c0 72 -82 88 -104 92c-72 14 -100 20 -132 46 c-27 22 -43 50 -43 85c0 56 38 123 160 123c15 0 56 0 94 -28c4 3 14 12 17 16c13 12 15 12 20 12c11 0 11 -7 11 -24v-101c0 -19 0 -24 -13 -24c0 0 -11 0 -12 9c-2 31 -7 121 -117 121c-86 0 -112 -41 -112 -76c0 -58 67 -71 123 -82c42 -8 81 -16 114 -48 c12 -12 42 -42 42 -95Z"></path>
<path stroke-width="1" id="E1-LATINMODERNNORMAL-1D703" d="M455 500c0 -224 -152 -511 -293 -511c-91 0 -120 111 -120 205c0 229 154 511 293 511c102 0 120 -139 120 -205zM389 562c0 57 -6 121 -55 121c-45 0 -82 -56 -109 -105c-40 -71 -60 -151 -77 -215h209c24 99 32 150 32 199zM348 331h-208c-26 -98 -32 -156 -32 -198 c0 -93 21 -122 54 -122c43 0 81 49 116 117c38 72 59 157 70 203Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-LATINMODERNMAIN-63"></use>
 <use xlink:href="#E1-LATINMODERNMAIN-6F" x="444" y="0"></use>
 <use xlink:href="#E1-LATINMODERNMAIN-73" x="945" y="0"></use>
 <use xlink:href="#E1-LATINMODERNNORMAL-1D703" x="1506" y="0"></use>
</g>
</svg>
term from the scattering equation but also only generates samples in the
hemisphere around the surface normal.  More recently, Conty Estevez and
Lecocq (<a href="#cite:Conty2018:product">2018</a>) introduced a technique for sampling
according to the product of the BSDF and the environment map based on
discretizing the environment map into coarse grids of pixels,
conservatively evaluating the maximum of the BSDF over the corresponding
sets of directions, and then choosing a region of the environment map
according to the product of BSDF and pixel values.  Given a selected grid
cell, conventional environment map sampling is applied.   (See also the
&ldquo;Further Reading&rdquo; section in Chapter&nbsp;<a href="../Light_Transport_I_Surface_Reflection.html#chap:light-transport">13</a> for
further references to light and BSDF product sampling algorithms.)

</p>
<p>When environment maps are used for illuminating indoor scenes, many
incident directions may be blocked by the building structure.  Bitterli
et&nbsp;al. (<a href="#cite:Bitterli2015">2015</a>) developed the environment map
rectification approach to this problem that we have implemented in the
<a href="../Light_Sources/Infinite_Area_Lights.html#PortalImageInfiniteLight"><tt>PortalImageInfiniteLight</tt></a>.
One shortcoming of Bitterli et&nbsp;al.&rsquo;s approach is that the image must be
rectified for each plane in which there is a portal.  Ogaki
(<a href="#cite:Ogaki2020">2020</a>) addresses this issue by building a BVH over the
portals using Conty Estevez and Kulla&rsquo;s light BVH
(<a href="#cite:Conty2018:bvh">2018</a>) and then decomposing portals into triangles to
sample a specific direction according to the environment map.

</p>
<p>Sampling-based approaches can also be used to account for environment map
visibility.  Bashford-Rogers et&nbsp;al. (<a href="#cite:Bashford-Rogers2013">2013</a>)
developed a two-pass algorithm where a first pass from the camera finds
directions that reach the environment map; this information is used to
create sampling distributions for use in a second rendering pass.
Atanasov et&nbsp;al. (<a href="#cite:Atanasov2018">2018</a>) also applied a two-pass algorithm
to the task, furthermore discretizing regions of the scene in order to
account for different parts of the environment map being visible in
different regions of the scene.

</p>
<p>

</p>
<p></p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#x3-OptimizingVisibilityTesting"><i class="fas fa-link h3h4marginlink"></i></a>
</div>
<div class="col-md-10 col-lg-8">
<span id="x3-OptimizingVisibilityTesting"></span><h4>Optimizing Visibility Testing</h4><p>


</p>
<p>As discussed in Chapter&nbsp;<a href="../Shapes.html#chap:shapes">6</a>, one way to reduce the time spent
tracing shadow rays is to have methods like <a href="../Shapes/Basic_Shape_Interface.html#Shape::IntersectP"><tt>Shape::IntersectP()</tt></a> and
<a href="../Primitives_and_Intersection_Acceleration/Primitive_Interface_and_Geometric_Primitives.html#Primitive::IntersectP"><tt>Primitive::IntersectP()</tt></a> that just check for any occlusion along a ray
without bothering to compute the geometric information at the intersection
point.

</p>
<p>Another approach for optimizing ray tracing for shadow rays is the
<em>shadow cache</em>, where each light stores a pointer to the last
primitive that occluded a shadow ray to the light. That primitive is
checked first to see if it occludes subsequent shadow rays before the ray
is passed to the acceleration structure (<a href="#cite:Haines86">Haines and Greenberg 1986</a>).  Pearce
(<a href="#cite:Pearce91">1991</a>) pointed out that the shadow cache does not work well
if the scene has finely tessellated geometry; it may be better to cache the
BVH node that held the last occluder, for instance.  (The shadow cache can
similarly be defeated when multiple levels of reflection and refraction are
present or when Monte Carlo ray-tracing techniques are used.)  Hart et
al. (<a href="#cite:Hart99">1999</a>) developed a generalization of the shadow cache that
tracks which objects block light from particular light sources and clips
their geometry against the light-source geometry so that shadow rays do not
need to be traced toward the parts of the light that are certain to be
occluded.

</p>
<p>A related technique, described by Haines and Greenberg
(<a href="#cite:Haines86">1986</a>), is the <em>light buffer</em> for point light sources, where
the light discretizes the directions around it and determines which objects
are visible along each set of directions (and are thus potential occluding
objects for shadow rays).  A related optimization is <em>shaft
culling</em>, which takes advantage of coherence among groups of rays traced in
a similar set of directions (e.g., shadow rays from a single point to
points on an area light source).  With shaft culling, a shaft that bounds a
collection of rays is computed and then the objects in the scene that
penetrate the shaft are found.  For all the rays in the shaft, it is
only necessary to check for intersections with those objects that intersect
the shaft, and the expense of ray intersection acceleration structure
traversal for each of the rays is avoided (<a href="#cite:Haines94">Haines and Wallace 1994</a>).

</p>
<p>Woo and Amanatides (<a href="#cite:Woo:1990:VOT">1990</a>) classified which lights are
visible, not visible, and partially visible in different parts of the scene
and stored this information in a voxel-based 3D data structure, using the
information to save shadow ray tests.  Fernandez, Bala, and Greenberg
(<a href="#cite:Fernandez:2002:LIE">2002</a>) developed a similar approach based on
spatial decomposition that stores references to important blockers in each
voxel and also builds up this information on demand during rendering.  A
related approach to reducing the cost of shadow rays is visibility caching,
where the point-to-point visibility function&rsquo;s value is cached for clusters
of points on surfaces in the scene (Clarberg and Akenine-M&ouml;ller
<a href="#cite:Clarberg2008b">2008b</a>; Popov et&nbsp;al. <a href="#cite:Popov2013">2013</a>).

</p>
<p>For complex models, simplified versions of their geometry can be used for
shadow ray intersections.  For example, the simplification envelopes
described by Cohen et al. (<a href="#cite:Cohen96">1996</a>) can create a simplified mesh
that bounds a given mesh from both the inside and the outside.  If a ray
misses the mesh that bounds a complex model from the outside or intersects
the mesh that bounds it from the inside, then no further shadow processing
is necessary.  Only the uncertain remaining cases need to be intersected
against the full geometry.  A related technique is described by Lukaszewski
(<a href="#cite:Lukaszewski01">2001</a>), who uses the Minkowski sum to effectively
expand primitives (or bounds of primitives) in the scene so that
intersecting one ray against one of these primitives can determine if any
of a collection of rays might have intersected the actual primitives.

</p>
<p>The expense of tracing shadow rays to light sources can be significant; a
number of techniques have been developed to improve the
efficiency of this part of the rendering computation.  Billen
et&nbsp;al. (<a href="#cite:Billen2013">2013</a>) tested only a random
subset of potential occluders for intersections; a compensation
term ensured that the result was unbiased. Following work showed how to use
simplified geometry for some shadow tests while still computing the correct
result overall (Billen et&nbsp;al.&nbsp;<a href="#cite:Billen2014">2014</a>). 

</p>
<p>

</p>
<p></p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#x3-Many-LightSampling"><i class="fas fa-link h3h4marginlink"></i></a>
</div>
<div class="col-md-10 col-lg-8">
<span id="x3-Many-LightSampling"></span><h4>Many-Light Sampling</h4><p>


</p>
<p>A number of approaches have been developed to efficiently render scenes
with hundreds or thousands of light sources.  Early work on this problem was
done by Ward (<a href="#cite:Ward91">1991</a>) and Shirley et&nbsp;al. (<a href="#cite:Shirley96">1996</a>).

</p>
<p>Wald et&nbsp;al. (<a href="#cite:Wald03">2003</a>) suggested rendering an image with path
tracing and a very low sampling rate (e.g., one path per pixel), recording
information about which of the light sources made some contribution to the
image.  This information is then used to set probabilities for sampling
each light.  Donikian et&nbsp;al. (<a href="#cite:Donikian2006">2006</a>) adaptively found
PDFs for sampling lights through an iterative process of taking a number of
light samples, noting which ones were effective, and reusing this
information at nearby pixels.  The &ldquo;lightcuts&rdquo; algorithm, described in
the &ldquo;Further Reading&rdquo; section of

Chapter&nbsp;<a href="../Light_Transport_I_Surface_Reflection.html#chap:light-transport">13</a>,


also addresses this problem.

</p>
<p>Tokuyoshi and Harada (<a href="#cite:Tokuyoshi2016">2016</a>) organized lights in trees of
bounding spheres and stochastically culled them when shading.  Conty Estevez
and Kulla (<a href="#cite:Conty2018:bvh">2018</a>) organized lights in BVHs and introduced
effective approaches for building light BVHs and sampling lights stored in
them. <tt>pbrt</tt>&rsquo;s <a href="../Light_Sources/Light_Sampling.html#BVHLightSampler"><tt>BVHLightSampler</tt></a> is directly based on their approach.
(The <em>Iray</em> renderer uses a BVH in a similar fashion for light
sampling (<a href="#cite:Keller2017">Keller et al. 2017</a>).)  Conty Estevez and Kulla&rsquo;s approach was
subsequently improved by Liu et&nbsp;al. (<a href="#cite:Liu2019">2019b</a>), who incorporated
the BSDF in the sampling weight computations.

</p>
<p>Incorporating light visibility into the sampling process can substantially
improve the results. V&eacute;voda et&nbsp;al. (<a href="#cite:Vevoda2018">2018</a>) clustered
lights and tracked visibility to them, applying Bayesian regression to learn
how to effectively sample lights. Guo et&nbsp;al. (<a href="#cite:Guo2020">2020</a>) cached
information about voxel-to-voxel visibility in a discretization of the
scene, which can either be used for Russian roulette or for light
importance sampling.  Bitterli et&nbsp;al. (<a href="#cite:Bitterli2020">2020</a>) showed how to
apply spatial and temporal resampling of light samples that include
visibility in order to achieve high-quality results with few shadow rays
per pixel.

</p>
<p>The &ldquo;bit trail&rdquo; technique used to encode the path from the root to each
light at the leaves of <tt>pbrt</tt>&rsquo;s <a href="../Light_Sources/Light_Sampling.html#BVHLightSampler"><tt>BVHLightSampler</tt></a> is due to Laine
(<a href="#cite:Laine2010">2010</a>).

</p>
<p></p>
<h3>References</h3>
<ol style="list-style: none;">
<li class="bibitem" id="cite:Ashdown:1993:NPA">Ashdown, I. 1993.
Near-field photometry: A new approach.
<em>Journal of the Illuminating Engineering Society</em>&nbsp;<em>22</em>&thinsp;(1), 163&ndash;80.
</li>

<li class="bibitem" id="cite:Atanasov2018">Atanasov, A., V.&nbsp;Koylazov, B.&nbsp;Taskov, A.&nbsp;Soklev, V.&nbsp;Chizhov, and J.&nbsp;K<span>&#345;</span>iv&aacute;nek. 2018.
Adaptive environment sampling on CPU and GPU.
In <em>ACM SIGGRAPH 2018 Talks</em>, 68:1&ndash;2.
</li>

<li class="bibitem" id="cite:Barzel97">Barzel, R. 1997.
Lighting controls for computer cinematography.
<em>Journal of Graphics Tools</em>&nbsp;<em>2</em>&thinsp;(1), 1&ndash;20.
</li>

<li class="bibitem" id="cite:Bashford-Rogers2013">Bashford-Rogers, T., K.&nbsp;Debattista, and A.&nbsp;Chalmers. 2013.
Importance driven environment map sampling.
<em>IEEE Transactions on Visualization and Computer
Graphics</em>&nbsp;<em>20</em>&thinsp;(6), 907&ndash;18.
</li>

<li class="bibitem" id="cite:Billen2014">Billen, N., A.&nbsp;Lagae, and P.&nbsp;Dutr&eacute;. 2014.
Probabilistic visibility evaluation using geometry proxies. 
<em>Computer Graphics Forum (Proceedings of the 2014 Eurographics Symposium on
Rendering)</em> <em>33</em>&thinsp;(4), 143&ndash;52.
</li>

<li class="bibitem" id="cite:Billen2013">Billen, N., B.&nbsp;Engelen, A.&nbsp;Lagae, and P.&nbsp;Dutr&eacute;. 2013.
Probabilistic visibility evaluation for direct illumination.
<em>Computer Graphics Forum (Proceedings of the 2013 Eurographics Symposium on
Rendering)</em>&nbsp;<em>32</em>&thinsp;(4), 39&ndash;47.
</li>

<li class="bibitem" id="cite:Bitterli2020">Bitterli, B., C.&nbsp;Wyman, M.&nbsp;Pharr, P.&nbsp;Shirley, A.&nbsp;Lefohn, and W.&nbsp;Jarosz. 2020.
Spatiotemporal reservoir resampling for real-time ray tracing with dynamic direct lighting. 
<em>ACM Transactions on Graphics (Proceedings of
SIGGRAPH)</em>&nbsp;<em>39</em>&thinsp;(4), 148:1&ndash;17.
</li>

<li class="bibitem" id="cite:Bitterli2015">Bitterli, B., J.&nbsp;Nov&aacute;k, and W.&nbsp;Jarosz. 2015.
Portal-masked environment map sampling. 
<em>Computer Graphics Forum (Proceedings of the 2015
Eurographics Symposium on Rendering)</em>&nbsp;<em>34</em>&thinsp;(4), 13&ndash;19.
</li>

<li class="bibitem" id="cite:Bjorke01">Bjorke, K. 2001.
Using Maya with RenderMan on Final Fantasy: The Spirits
  Within.
<em>SIGGRAPH 2001 RenderMan Course Notes.</em>
</li>

<li class="bibitem" id="cite:Blinn76">Blinn, J.&nbsp;F., and M.&nbsp;E. Newell. 1976.
Texture and reflection in computer generated images.
<em>Communications of the ACM</em>&nbsp;<em>19</em>, 542&ndash;46.
</li>

<li class="bibitem" id="cite:Clarberg2008b">Clarberg, P., and T.&nbsp;Akenine-M&ouml;ller. 2008b.
Exploiting visibility correlation in direct illumination.
<em>Computer Graphics Forum (Proceedings of the 2008 Eurographics Symposium on
Rendering)</em>&nbsp;<em>27</em>&thinsp;(4), 1125&ndash;36.
</li>

<li class="bibitem" id="cite:Cohen96">Cohen, J., A.&nbsp;Varshney, D.&nbsp;Manocha, G.&nbsp;Turk, H.&nbsp;Weber, P.&nbsp;Agarwal, F.&nbsp;P.
  Brooks Jr., and W.&nbsp;Wright. 1996.
Simplification envelopes.
In <em>Proceedings of SIGGRAPH &rsquo;96</em>, Computer Graphics Proceedings,
  Annual Conference Series, 119&ndash;28.
</li>

<li class="bibitem" id="cite:Conty2018:bvh">Conty Estevez, A., and C.&nbsp;Kulla. 2018.
Importance sampling of many lights with adaptive tree splitting.
<em>Proceedings of the ACM on Computer Graphics and Interactive
Techniques</em>&nbsp;<em>1</em>&thinsp;(2), 25:1&ndash;17.
</li>

<li class="bibitem" id="cite:Conty2018:product">Conty Estevez, A., and P.&nbsp;Lecocq. 2018.
Fast product importance sampling of environment maps.
<em>ACM SIGGRAPH 2018 Talks</em>&nbsp;69, 1&ndash;2.
</li>

<li class="bibitem" id="cite:Debevec98">Debevec, P. 1998.
Rendering synthetic objects into real scenes: Bridging traditional
  and image-based graphics with global illumination and high dynamic range
  photography.
In <em>Proceedings of SIGGRAPH &rsquo;98</em>, 189&ndash;98.
</li>

<li class="bibitem" id="cite:Donikian2006">Donikian, M., B.&nbsp;Walter, K.&nbsp;Bala, S.&nbsp;Fernandez, and D.&nbsp;P. Greenberg. 2006.
Accurate direct illumination using iterative adaptive sampling.
<em>IEEE Transactions on Visualization and Computer Graphics</em>&nbsp;<em>12</em>&thinsp;(3),
353&ndash;64.
</li>

<li class="bibitem" id="cite:Dorsey:1991:DAS">Dorsey, J.&nbsp;O., F.&nbsp;X. Sillion, and D.&nbsp;P. Greenberg. 1991.
Design and simulation of opera lighting and projection effects.
In <em>Computer Graphics (Proceedings of SIGGRAPH &rsquo;91)</em> <em>25</em>,
41&ndash;50.
</li>

<li class="bibitem" id="cite:Fernandez:2002:LIE">Fernandez, S., K.&nbsp;Bala, and D.&nbsp;P. Greenberg. 2002.
Local illumination environments for direct lighting acceleration.
<em>Rendering Techniques 2002: 13th Eurographics Workshop on
  Rendering</em>, 7&ndash;14.
</li>

<li class="bibitem" id="cite:Goesele2003">Goesele, M., X.&nbsp;Granier, W.&nbsp;Heidrich, and H.-P.&nbsp;Seidel. 2003.
Accurate light source acquisition and rendering.
<em>ACM Transactions on Graphics (Proceedings of SIGGRAPH
2003)</em>&nbsp;<em>22</em>&thinsp;(3), 621&ndash;30.
</li>

<li class="bibitem" id="cite:Greene86b">Greene, N. 1986.
Environment mapping and other applications of world projections.
<em>IEEE Computer Graphics and Applications</em>&nbsp;<em>6</em>&thinsp;(11),
  21&ndash;29.
</li>

<li class="bibitem" id="cite:Guo2020">Guo, J.&nbsp;J., M.&nbsp;Eisemann, and E.&nbsp;Eisemann. 2020.
Next event estimation++: Visibility mapping for efficient light transport simulation.
<em>Computer Graphics Forum</em>&nbsp;<em>39</em>&thinsp;(7), 205&ndash;17.
</li>

<li class="bibitem" id="cite:Haines86">Haines, E.&nbsp;A., and D.&nbsp;P. Greenberg. 1986.
The light buffer: A shadow testing accelerator.
<em>IEEE Computer Graphics and Applications</em>&nbsp;<em>6</em>&thinsp;(9), 6&ndash;16.
</li>

<li class="bibitem" id="cite:Haines94">Haines, E.&nbsp;A., and J.&nbsp;R. Wallace. 1994.
Shaft culling for efficient ray-traced radiosity.
<em>Second Eurographics Workshop on Rendering (Photorealistic
  Rendering in Computer Graphics)</em>, 122&ndash;38.
Also in <em>SIGGRAPH 1991 Frontiers in Rendering Course Notes.</em>
</li>

<li class="bibitem" id="cite:Hart99">Hart, D., P.&nbsp;Dutr&eacute;, and D.&nbsp;P. Greenberg. 1999.
Direct illumination with lazy visibility evaluation.
<em>Proceedings of SIGGRAPH &rsquo;99</em>, Computer Graphics Proceedings,
  Annual Conference Series, 147&ndash;54.
</li>

<li class="bibitem" id="cite:Heidrich98a">Heidrich, W., J.&nbsp;Kautz, P.&nbsp;Slusallek, and H.-P. Seidel.  1998.
Canned lightsources.
In <em>Rendering Techniques &rsquo;98: Proceedings of the Eurographics Rendering
Workshop</em>,  293&ndash;300.
</li>

<li class="bibitem" id="cite:Heitz2016">Heitz, E., J.&nbsp;Dupuy, S.&nbsp;Hill, and D.&nbsp;Neubelt. 2016a.
Real-time polygonal-light shading with linearly transformed cosines.
<em>ACM Transactions on Graphics (Proceedings of
SIGGRAPH)</em>&nbsp;<em>35</em>&thinsp;(4), 41:1&ndash;8.
</li>

<li class="bibitem" id="cite:IESNA2002">Illuminating Engineering Society of North America. 2002.
IESNA standard file format for electronic transfer of photometric
  data.
BSR/IESNA Publication LM-63-2002. <a href="http://www.iesna.org.">www.iesna.org.</a>
</li>

<li class="bibitem" id="cite:Karlik2019">Karl&iacute;k, O., M.&nbsp;<span>&#352;</span>ik, P.&nbsp;V&eacute;voda, T.&nbsp;Sk<span>&#345;</span>ivan, and
 J.&nbsp;K<span>&#345;</span>iv&aacute;nek. 2019.
MIS compensation: Optimizing sampling techniques in multiple importance sampling.
<em>ACM Transactions on Graphics (Proceedings of
 SIGGRAPH Asia)</em>&nbsp;<em>38</em>&thinsp;(6), 151:1&ndash;12.
</li>

<li class="bibitem" id="cite:Keller2017">Keller, A., C.&nbsp;W&auml;chter, M.&nbsp;Raab, D.&nbsp;Seibert, D.&nbsp;van Antwerpen,
J.&nbsp;Kornd&ouml;rfer, and L.&nbsp;Kettner. 2017.
The Iray light transport simulation and rendering system.
arXiv:1705.01263 [cs.GR].
</li>

<li class="bibitem" id="cite:Kider2014">Kider Jr., J.&nbsp;T., D.&nbsp;Knowlton, J.&nbsp;Newlin, Y.&nbsp;K.&nbsp;Li, and D.&nbsp;P.&nbsp;Greenberg. 2014.
A framework for the experimental comparison of solar and skydome
illumination.
<em>ACM Transactions on Graphics (Proceedings of SIGGRAPH
Asia 2014)</em>&nbsp;<em>33</em>&thinsp;(6), 180:1&ndash;12.
</li>

<li class="bibitem" id="cite:Kniep2009">Kniep, S., S.&nbsp;H&auml;ring, and M.&nbsp;Magnor. 2009.
Efficient and accurate rendering of complex light sources.
<em>Computer Graphics Forum (Proceedings of the 2009 Eurographics
Symposium on Rendering)</em>&nbsp;<em>28</em>&thinsp;(4), 1073&ndash;81.
</li>

<li class="bibitem" id="cite:Laine2010">Laine, S. 2010.
Restart trail for stackless BVH traversal. 
In <em>Proceedings of High Performance Graphics 2010</em>, 107&ndash;11.
</li>

<li class="bibitem" id="cite:Liu2019">Liu, Y., K.&nbsp;Xu, and L.-Q.&nbsp;Yan. 2019b.
Adaptive BRDF-oriented multiple importance sampling of many lights.
<em>Computer Graphics Forum</em>&nbsp;<em>38</em>&thinsp;(4), 123&ndash;33.
</li>

<li class="bibitem" id="cite:Lu2015">Lu, H., R.&nbsp;Pacanowski, and X.&nbsp;Granier. 2015.
Position-dependent importance sampling of light field luminaires.
<em>IEEE Transactions on Visualization and Computer
Graphics</em>&nbsp;<em>21</em>&thinsp;(2), 241&ndash;51.
</li>

<li class="bibitem" id="cite:Lukaszewski01">Lukaszewski, A. 2001.
Exploiting coherence of shadow rays.
In <em>AFRIGRAPH 2001</em>, 147&ndash;50. ACM SIGGRAPH.
</li>

<li class="bibitem" id="cite:Mas2008">Mas, A., I.&nbsp;Mart&iacute;n, and G.&nbsp;Patow. 2008.
Compression and importance sampling of near-field light sources.
<em>Computer Graphics Forum</em>&nbsp;<em>27</em>&thinsp;(8), 2013&ndash;27.
</li>

<li class="bibitem" id="cite:Miller84">Miller, G.&nbsp;S., and C.&nbsp;R. Hoffman. 1984.
Illumination and reflection maps: Simulated objects in simulated and
  real environments.
<em>Course Notes for Advanced Computer Graphics Animation, SIGGRAPH &rsquo;84.</em>
</li>

<li class="bibitem" id="cite:Nishita:1986:CTR">Nishita, T., and E.&nbsp;Nakamae. 1986.
Continuous tone representation of three-dimensional objects
  illuminated by sky light.
In <em>Computer Graphics (Proceedings of SIGGRAPH &rsquo;86)</em>, Volume&nbsp;20,
  125&ndash;32.
</li>

<li class="bibitem" id="cite:Ogaki2020">Ogaki, S. 2020.
Generalized light portals.
<em>Proceedings of the ACM on Computer Graphics and Interactive
Techniques</em>&nbsp;<em>3</em>&thinsp;(2), 10:1&ndash;19.
</li>

<li class="bibitem" id="cite:Pearce91">Pearce, A. 1991.
A recursive shadow voxel cache for ray tracing.
In J.&nbsp;Arvo (ed.), <em>Graphics Gems II</em>, 273&ndash;74. San Diego: Academic
  Press.
</li>

<li class="bibitem" id="cite:Peters2021linear">Peters, C. 2021a.
BRDF importance sampling for linear lights.
<em>Computer Graphics Forum (Proceedings of High Performance
Graphics)</em>&nbsp;<em>40</em>&thinsp;(8), 31&ndash;40.
</li>

<li class="bibitem" id="cite:Popov2013">Popov, S., I.&nbsp;Georgiev, P.&nbsp;Slusallek, and C.&nbsp;Dachsbacher. 2013.
Adaptive quantization visibility caching.
<em>Computer Graphics Forum (Proceedings of Eurographics 2013)</em>&nbsp;<em>32</em>&thinsp;(2),
399&ndash;408.
</li>

<li class="bibitem" id="cite:Shirley96">Shirley, P., C.&nbsp;Y. Wang, and K.&nbsp;Zimmerman. 1996.
Monte Carlo techniques for direct lighting calculations.
<em>ACM Transactions on Graphics</em>&nbsp;<em>15</em>&thinsp;(1), 1&ndash;36.
</li>

<li class="bibitem" id="cite:Subr07b">Subr, K., and J.&nbsp;Arvo. 2007b.
Steerable importance sampling.
<em>IEEE Symposium on Interactive Ray Tracing</em>, 133&ndash;40.
</li>

<li class="bibitem" id="cite:Tokuyoshi2016">Tokuyoshi, Y., and T.&nbsp;Harada. 2016.
Stochastic light culling.
<em>Journal of Computer Graphics Techniques (JCGT)</em>&nbsp;<em>5</em>&thinsp;(1),
35&ndash;60.
</li>

<li class="bibitem" id="cite:Unger2003">Unger, J., A.&nbsp;Wenger, T.&nbsp;Hawkins, A.&nbsp;Gardner, and P.&nbsp;Debevec. 2003.
Capturing and rendering with incident light fields.
In <em>Proceedings of the Eurographics Rendering Workshop 2003</em>, 141&ndash;49.
</li>

<li class="bibitem" id="cite:Unger2008">Unger, J., S.&nbsp;Gustavson, P.&nbsp;Larsson, and A.&nbsp;Ynnerman. 2008.
Free form incident light fields.
<em>Computer Graphics Forum (Proceedings of the 2008 Eurographics
Symposium on Rendering)</em>&nbsp;<em>27</em>&thinsp;(4), 1293&ndash;1301.
</li>

<li class="bibitem" id="cite:Vevoda2018">V&eacute;voda, P., I.&nbsp;Kondapaneni, and J.&nbsp;K<span>&#345;</span>iv&aacute;nek. 2018.
Bayesian online regression for adaptive direct illumination sampling.
<em>ACM Transactions on Graphics (Proceedings of
SIGGRAPH)</em>&nbsp;<em>37</em>&thinsp;(4), 125:1&ndash;12.
</li>

<li class="bibitem" id="cite:Velazquez-Armendariz2015">Vel&aacute;zquez-Armend&aacute;riz, E., Z.&nbsp;Dong, B.&nbsp;Walter, and D.&nbsp;P.&nbsp;Greenberg. 2015.
Complex luminaires: Illumination and appearance rendering.
<em>ACM Transactions on Graphics (Proceedings of SIGGRAPH 2015)</em>&nbsp;<em>34</em>&thinsp;(3),
26:1&ndash;15.
</li>

<li class="bibitem" id="cite:Verbeck:1984:ACL">Verbeck, C.&nbsp;P., and D.&nbsp;P. Greenberg. 1984.
A comprehensive light source description for computer graphics.
<em>IEEE Computer Graphics and Applications</em>&nbsp;<em>4</em>&thinsp;(7),
  66&ndash;75.
</li>

<li class="bibitem" id="cite:Wald03">Wald, I., C.&nbsp;Benthin, and P.&nbsp;Slusallek. 2003.
Interactive global illumination in complex and highly occluded
  environments.
In <em>Eurographics Symposium on Rendering: 14th Eurographics
  Workshop on Rendering</em>, 74&ndash;81.
</li>

<li class="bibitem" id="cite:Ward91">Ward, G. 1991.
Adaptive shadow testing for ray tracing.
In <em>Second Eurographics Workshop on Rendering</em>.
</li>

<li class="bibitem" id="cite:Warn83">Warn, D.&nbsp;R. 1983.
Lighting controls for synthetic images.
In <em>Computer Graphics (Proceedings of SIGGRAPH &rsquo;83)</em>, Volume&nbsp;17,
  13&ndash;21.
</li>

<li class="bibitem" id="cite:Woo:1990:VOT">Woo, A., and J.&nbsp;Amanatides. 1990.
Voxel occlusion testing: A shadow determination accelerator for ray
  tracing.
In <em>Proceedings of Graphics Interface 1990</em>, 213&ndash;20.
</li>

<li class="bibitem" id="cite:Zhu2021:luminaires">Zhu, J., Y.&nbsp;Bai, Z.&nbsp;Xu, S.&nbsp;Bako, E.&nbsp;Vel&aacute;zquez-Armend&aacute;riz, L.&nbsp;Wang, P.&nbsp;Sen, M.&nbsp;Ha<span>&#353;</span>an, and L.-Q.&nbsp;Yan. 2021.
Neural complex luminaires: Representation and rendering.
<em>ACM Transactions on Graphics (Proceedings of
SIGGRAPH)</em>&nbsp;<em>40</em>&thinsp;(4), 57:1&ndash;12.
</li>

</ol>
<p>


</p>
<p>

</p>
<p></p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

</div>  <!-- container-fluid -->
</div>  <!-- maincontainer -->

<nav class="navbar navbar-expand-md bg-light navbar-light">
<div class="container-fluid">
  <span class="navbar-text"><i>Physically Based Rendering: From Theory To Implementation</i>,<br>
<a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">&copy; 2004-2023</a> Matt Pharr, Wenzel Jakob, and Greg Humphreys.
<a href="https://github.com/mmp/pbr-book-website/"><span class="fab fa-github"></span></a><br>
Purchase a printed copy: <a href="https://www.amazon.com/Physically-Based-Rendering-fourth-Implementation/dp/0262048027?keywords=physically+based+rendering+4th+edition&qid=1671730412&sprefix=physically+based%!C(MISSING)aps%!C(MISSING)145&sr=8-1&linkCode=ll1&tag=pharr-20&linkId=81a816d90f0c7e872617f1f930a51fd6&language=en_US&ref_=as_li_ss_tl"><span class="fab fa-amazon"></span></a>
<a href="https://mitpress.mit.edu/9780262048026/physically-based-rendering/"><img src="/mitpress.png" width=10 height=16></a>
</span>
</div>
  <div class="container">
    <ul class="nav navbar-nav ml-auto">
      <li class="nav-item">Next: <a href="../Light_Sources/Exercises.html">Light Sources / Exercises</a></li>
    </ul>
  </div>

</nav>

<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script>
  $(function () {
    $('[data-toggle="popover"]').popover()
    $('[data-toggle="tooltip"]').tooltip()
   })
</script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

<script>
// https://stackoverflow.com/a/17535094
// The function actually applying the offset
function offsetAnchor() {
  if (location.hash.length !== 0) {
    window.scrollTo(window.scrollX, window.scrollY - window.innerHeight / 8);
  }
}

// Captures click events of all <a> elements with href starting with #
$(document).on('click', 'a[href^="#"]', function(event) {
  // Click events are captured before hashchanges. Timeout
  // causes offsetAnchor to be called after the page jump.
  window.setTimeout(function() {
    offsetAnchor();
  }, 500);
});

// Set the offset when entering page with hash present in the url
window.setTimeout(offsetAnchor, 1500);
</script>

</body>
</html>
