
<!doctype html>
<html lang="en">
<head>

<!-- all praise to https://realfavicongenerator.net -->
<link rel="icon" href="/favicon.ico?v=2" /> <!-- force refresh -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="/fonts.css">
  <link rel="stylesheet" href="../pbrstyle.css">
  <link rel="stylesheet" href="/fontawesome-free-5.15.3-web/css/all.css">

  <script async src="https://cse.google.com/cse.js?cx=003601324460585362024:4xwpwgaitgd"></script>
  <script src="/react.min.js"></script>
  <script src="/react-dom.min.js"></script>
  <script src="/jeri.min.js"></script>
  <link rel="preload" href="/exr.worker.js" as="script" crossorigin="anonymous">
        
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="/bootstrap.min.css">

  <title>Exercises</title>
</head>
        
<body>

<nav class="fixed-top-lg-navbar navbar navbar-expand bg-light navbar-light">
  <ul class="nav navbar-nav">
    <a class="navbar-brand" href="../contents.html"><img src="../pbr.jpg" width=25 height=25></a>
    <li class="nav-item"><a class="nav-link" href="../Cameras_and_Film.html">Cameras and Film</a></li>
    <span class="navbar-text">/</span>
    <li class="nav-item"><a class="nav-link" href="#">Exercises</a></li>
    <span class="navbar-text">&nbsp;&nbsp;</span>
    <li class="nav-item"><a class="nav-link" href="../Cameras_and_Film/Further_Reading.html">(Previous: Further Reading)</a></li>
  </ul>

  <ul class="nav navbar-nav ml-auto d-none d-md-block">
        <li class="nav-item"><div class="gcse-search"></div></li>
    </ul>
  <ul class="nav navbar-nav d-block d-md-none">
        <li class="nav-item"><div class="gcse-search"></div></li>
    </ul>
</nav>

<div class="maincontainer">
<div class="container-fluid">

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">

</div>
<div class="col-md-10 col-lg-8">

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#"><i class="fas fa-link "></i></a>
</div>
<div class="col-md-10 col-lg-8">
<h2>Exercises</h2><p>


</p>
<p></p>
<ol>

 <li class="exercise"><span class="exerciseicon">&#9313;</span> Some types of cameras expose the film by sliding a
rectangular slit across the film.  This leads to interesting effects when
objects are moving in a different direction from the exposure slit
(Glassner <a href="Further_Reading.html#cite:Glassner1999">1999</a>; Stephenson <a href="Further_Reading.html#cite:Stephenson07">2007</a>).
Furthermore, most digital cameras read
out pixel values from scanlines in succession over a period of a few
milliseconds; this leads to <em>rolling shutter</em> artifacts, which have
similar visual characteristics.  Modify the way that time samples are
generated in one or more of the camera implementations in this chapter to
model such effects. Render images with moving objects that clearly show
the effect of accounting for this issue.

 <li class="exercise"><span class="exerciseicon">&#9313;</span> Write an application that loads images rendered by the
<a href="../Cameras_and_Film/Spherical_Camera.html#SphericalCamera"><tt>SphericalCamera</tt></a> and uses texture mapping to apply them to a sphere
centered at the eyepoint such that they can be viewed interactively.  The
user should be able to freely change the viewing direction.  If the
correct texture-mapping function is used for generating texture
coordinates on the sphere, the image generated by the application will
appear as if the viewer was at the camera&rsquo;s location in the scene when it
was rendered, thus giving the user the ability to interactively look around
the scene.

 <li class="exercise"><span class="exerciseicon">&#9313;</span> <em>Focal stack rendering:</em> A focal stack is a series
of images of a fixed scene where the camera is focused at a different
distance for each image.  Hasinoff and Kutulakos (<a href="Further_Reading.html#cite:Hasinoff2011">2011</a>)
and Jacobs et al. (<a href="Further_Reading.html#cite:Jacobs2012">2012</a>) introduced a number of
applications of focal stacks, including freeform depth of field, where the
user can specify arbitrary depths that are in focus, achieving effects not
possible with traditional optics.  Render focal stacks with <tt>pbrt</tt> and
write an interactive tool to control focus effects with them.

 <li class="exercise"><span class="exerciseicon">&#9314;</span> <em>Light field camera:</em> Ng et al. (<a href="Further_Reading.html#cite:Ng2005">2005</a>)
discussed the physical design and applications of a camera that captures
small images of the exit pupil across the film, rather than averaging the
radiance over the entire exit pupil at each pixel, as conventional cameras
do.  Such a camera captures a representation of the <em>light
field</em>&mdash;the spatially and directionally varying distribution of radiance
arriving at the camera sensor.  By capturing the light field, a number of
interesting operations are possible, including refocusing photographs after
they have been taken.  Read Ng et al.&rsquo;s paper and implement a <tt>Camera</tt>
in <tt>pbrt</tt> that captures the light field of a scene.  Write a tool to allow
users to interactively refocus these light fields.



 <li class="exercise"><span class="exerciseicon">&#9314;</span> The <tt>Camera</tt>s in this chapter place the film at
the center of and perpendicular to the optical axis.  While this is the
most common configuration of actual cameras, interesting effects can be
achieved by adjusting the film&rsquo;s placement with respect to the lens system.

For example, the plane of focus in the current implementation is always
perpendicular to the optical axis; if the film plane (or the lens system)
is tilted so that the film is not perpendicular to the optical axis, then
the plane of focus is no longer perpendicular to the optical axis.  (This
can be useful for landscape photography, for example, where aligning the
plane of focus with the ground plane allows greater depth of field even
with larger apertures.)  Alternatively, the film plane can be shifted so
that it is not centered on the optical axis; this shift can be used to keep
the plane of focus aligned with a very tall object, for example.


Modify the <tt>PerspectiveCamera</tt> to
allow one or both of these adjustments and render images showing the
result.  (You may find Kensler&rsquo;s
(<a href="Further_Reading.html#cite:Kensler2021">2021</a>) chapter useful.)




 <li class="exercise"><span class="exerciseicon">&#9313;</span> The clamping approach used to suppress outlier sample
values in the <tt>RGBFilm</tt> and <tt>GBufferFilm</tt> is a
heavy-handed solution that can cause a significant amount of energy loss in
the image. (Consider, for example, pixels where the sun is directly
visible&mdash;the radiance along rays in those pixels may be extremely high,
though it is not a cause of spiky pixels and should not be clamped.)
Implement a more principled solution to this problem such as the technique
of Zirr et al. (<a href="Further_Reading.html#cite:Zirr2018">2018</a>).  Render images with your
implementation and <tt>pbrt</tt>&rsquo;s current approach and compare the results.

 <li class="exercise"><span class="exerciseicon">&#9313;</span> Investigate the sources of noise in camera sensors and
mathematical models to simulate them.  Then, modify the <a href="../Cameras_and_Film/Film_and_Imaging.html#PixelSensor"><tt>PixelSensor</tt></a>
class to model the effect of noise. In addition to shot noise, which
depends on the number of photons reaching each pixel, you may also want to
model factors like read noise and dark noise, which are independent of the
number of photons.  Render images that exhibit noise and show the effect of
different types of it as exposure time varies.

 <li class="exercise"><span class="exerciseicon">&#9313;</span> Because they are based on floating-point addition, which
is not associative, the <tt>AddSplat()</tt> methods implemented in this
chapter do not live up to <tt>pbrt</tt>&rsquo;s goal of producing deterministic output:
if different threads add splats to the same pixel in a different order over
multiple runs of <tt>pbrt</tt>, the final image may differ.  An alternative
implementation might allocate a separate buffer for each thread&rsquo;s splats
and then sum the buffers at the end of rendering, which would be
deterministic but would incur a memory cost proportional to the number of
threads.  Either implement that approach or come up with another one to
address this issue and implement it in <tt>pbrt</tt>.  Measure the memory and performance
overhead of your approach as well as how often the current implementation
is non-deterministic.  Is the current implementation defensible?

 <li class="exercise"><span class="exerciseicon">&#9314;</span> Image-based rendering is the general name for a set of
techniques that use one or more images of a scene to synthesize new images
from viewpoints different from the original ones.  One such approach is
light field rendering, where a set of images from a densely spaced set of
positions is used&mdash;as described by <a href="Further_Reading.html#cite:Levoy96">Levoy and Hanrahan</a>
(<a href="Further_Reading.html#cite:Levoy96">1996</a>) and Gortler et al.&nbsp;(<a href="Further_Reading.html#cite:Gortler96">1996</a>).
Read these two papers on light fields, and modify <tt>pbrt</tt> to directly
generate light fields of scenes, without requiring that the renderer be run
multiple times, once for each camera position.  It will probably be
necessary to write a specialized <tt>Camera</tt>, <tt>Sampler</tt>, and
<tt>Film</tt> to do this.  Also, write an interactive light field viewer that
loads light fields generated by your implementation and that generates new views
of the scene.

</ol><p>


</p>
<p>

</p>
<p>

</p>
<p>

</p>
<p>

</p>
<p>

</p>
<p>


</p>
<p>

</p>
<p></p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

</div>  <!-- container-fluid -->
</div>  <!-- maincontainer -->

<nav class="navbar navbar-expand-md bg-light navbar-light">
<div class="container-fluid">
  <span class="navbar-text"><i>Physically Based Rendering: From Theory To Implementation</i>,<br>
<a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">&copy; 2004-2023</a> Matt Pharr, Wenzel Jakob, and Greg Humphreys.
<a href="https://github.com/mmp/pbr-book-website/"><span class="fab fa-github"></span></a><br>
Purchase a printed copy: <a href="https://www.amazon.com/Physically-Based-Rendering-fourth-Implementation/dp/0262048027?keywords=physically+based+rendering+4th+edition&qid=1671730412&sprefix=physically+based%!C(MISSING)aps%!C(MISSING)145&sr=8-1&linkCode=ll1&tag=pharr-20&linkId=81a816d90f0c7e872617f1f930a51fd6&language=en_US&ref_=as_li_ss_tl"><span class="fab fa-amazon"></span></a>
<a href="https://mitpress.mit.edu/9780262048026/physically-based-rendering/"><img src="/mitpress.png" width=10 height=16></a>
</span>
</div>
  <div class="container">
    <ul class="nav navbar-nav ml-auto">
      <li class="nav-item">Next: <a href="../Shapes.html">Shapes</a></li>
    </ul>
  </div>

</nav>

<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script>
  $(function () {
    $('[data-toggle="popover"]').popover()
    $('[data-toggle="tooltip"]').tooltip()
   })
</script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

<script>
// https://stackoverflow.com/a/17535094
// The function actually applying the offset
function offsetAnchor() {
  if (location.hash.length !== 0) {
    window.scrollTo(window.scrollX, window.scrollY - window.innerHeight / 8);
  }
}

// Captures click events of all <a> elements with href starting with #
$(document).on('click', 'a[href^="#"]', function(event) {
  // Click events are captured before hashchanges. Timeout
  // causes offsetAnchor to be called after the page jump.
  window.setTimeout(function() {
    offsetAnchor();
  }, 500);
});

// Set the offset when entering page with hash present in the url
window.setTimeout(offsetAnchor, 1500);
</script>

</body>
</html>
