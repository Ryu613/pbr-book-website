
<!doctype html>
<html lang="en">
<head>

<!-- all praise to https://realfavicongenerator.net -->
<link rel="icon" href="/favicon.ico?v=2" /> <!-- force refresh -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="/fonts.css">
  <link rel="stylesheet" href="../pbrstyle.css">
  <link rel="stylesheet" href="/fontawesome-free-5.15.3-web/css/all.css">

<script async src="https://cse.google.com/cse.js?cx=22a43cef261a245ea"></script>  <script src="/react.min.js"></script>
  <script src="/react-dom.min.js"></script>
  <script src="/jeri.min.js"></script>
  <link rel="preload" href="/exr.worker.js" as="script" crossorigin="anonymous">
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="/bootstrap.min.css">

  <title>Further Reading</title>
</head>
        
<body>

<nav class="fixed-top-lg-navbar navbar navbar-expand bg-light navbar-light">
  <ul class="nav navbar-nav">
    <a class="navbar-brand" href="../contents.html"><img src="../pbr.jpg" width=25 height=25></a>
    <li class="nav-item"><a class="nav-link" href="../Cameras_and_Film.html">Cameras and Film</a></li>
    <span class="navbar-text">/</span>
    <li class="nav-item"><a class="nav-link" href="#">Further Reading</a></li>
    <span class="navbar-text">&nbsp;&nbsp;</span>
    <li class="nav-item"><a class="nav-link" href="../Cameras_and_Film/Film_and_Imaging.html">(Previous: Film and Imaging)</a></li>
  </ul>

  <ul class="nav navbar-nav ml-auto d-none d-md-block">
        <li class="nav-item"><div class="gcse-search"></div></li>
    </ul>
  <ul class="nav navbar-nav d-block d-md-none">
        <li class="nav-item"><div class="gcse-search"></div></li>
    </ul>
</nav>

<div class="maincontainer">
<div class="container-fluid">

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">

</div>
<div class="col-md-10 col-lg-8">

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#"><i class="fas fa-link "></i></a>
</div>
<div class="col-md-10 col-lg-8">
<h2>Further Reading</h2><p>


</p>
<p>In his seminal <em>Sketchpad</em> system, Sutherland (<a href="#cite:Sutherland63">1963</a>) was
the first to use projection matrices for computer graphics.
Akenine-M&ouml;ller et al. (<a href="#cite:Moller18">2018</a>) have provided
a particularly well-written derivation of the orthographic and perspective
projection matrices.  Other good references for projections are Rogers and
Adams&rsquo;s <em>Mathematical Elements for Computer Graphics</em>
(<a href="#cite:Rogers90">1990</a>) and Eberly&rsquo;s book (<a href="#cite:Eberly01">2001</a>) on game
engine design.  See Adams and Levoy (<a href="#cite:Adams2007">2007</a>) for a broad
analysis of the types of radiance measurements that can be taken with
cameras that have non-pinhole apertures.

</p>
<p>An unusual projection method was used by Greene and Heckbert
(<a href="#cite:Greene86ewa">1986</a>) for generating images for OMNIMAX&reg; theaters.

</p>
<p>Potmesil and Chakravarty (<a href="#cite:Potmesil81">1981</a>, <a href="#cite:Potmesil82">1982</a>,
<a href="#cite:Potmesil83">1983</a>) did early work on depth of field and motion blur in
computer graphics.  Cook and collaborators developed a more accurate model
for these effects based on the thin lens model; this is the approach used
for the depth of field calculations in Section&nbsp;<a href="../Cameras_and_Film/Projective_Camera_Models.html#sec:thin-lens">5.2.3</a>
(<a href="#cite:Cook84">Cook et&nbsp;al. 1984</a>; <a href="#cite:Cook86">Cook 1986</a>).  An alternative approach to motion blur was
described by Gribel and Akenine-M&ouml;ller (<a href="#cite:Gribel2017">2017</a>), who
analytically computed the time ranges of ray&ndash;triangle intersections to
eliminate stochastic sampling in time.

</p>
<p>Kolb, Mitchell, and Hanrahan (<a href="#cite:Kolb95">1995</a>) showed how to simulate
complex camera lens systems with ray tracing in order to model the imaging
effects of real cameras; the <tt>RealisticCamera</tt> 
is based on their approach.  Steinert
et al. (<a href="#cite:Steinert2011">2011</a>) improved a number of details of this
simulation, incorporating wavelength-dependent effects and accounting for
both diffraction and glare.

Joo et
al. (<a href="#cite:Joo2016">2016</a>) extended this approach to handle aspheric lenses
and modeled diffraction at the aperture stop, which causes some
brightening at the edges of the circle of confusion in practice.  See the
books by Hecht (<a href="#cite:Hecht2002">2002</a>) and Smith (<a href="#cite:Smith2007">2007</a>) for
excellent introductions to optics and lens systems.

</p>
<p>Hullin et al. (<a href="#cite:Hullin2012">2012</a>) used polynomials to model the effect
of lenses on rays passing through them; they were able to construct
polynomials that approximate entire lens systems from polynomial
approximations of individual lenses.  This approach saves the computational
expense of tracing rays through lenses, though for complex scenes, this
cost is generally negligible in relation to the rest of the rendering
computations.  Hanika and Dachsbacher (<a href="#cite:Hanika2014">2014</a>) improved the
accuracy of this approach and showed how to combine it with bidirectional
path tracing. Schrade et al. (<a href="#cite:Schrade2016">2016</a>) showed good results
with approximation of wide-angle lenses using sparse higher-degree
polynomials.

</p>
<p>

</p>
<p></p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#x7-FilmandImaging"><i class="fas fa-link h3h4marginlink"></i></a>
</div>
<div class="col-md-10 col-lg-8">
<span id="x7-FilmandImaging"></span><h4>Film and Imaging</h4><p>


</p>
<p>The film sensor model presented in Section&nbsp;<a href="../Cameras_and_Film/Film_and_Imaging.html#sec:film-sensors">5.4.2</a> and the
<a href="../Cameras_and_Film/Film_and_Imaging.html#PixelSensor"><tt>PixelSensor</tt></a> class implementation are from the <em>PhysLight</em> system
described by Langlands and Fascione (<a href="#cite:Langlands2020">2020</a>).  See also
Chen et al. (<a href="#cite:Chen2009">2009</a>), who described the implementation of a
fairly complete simulation of a digital camera, including the
analog-to-digital conversion and noise in the measured pixel values
inherent in this process.

</p>
<p>Filter importance sampling, as described in
Section&nbsp;<a href="../Sampling_and_Reconstruction/Image_Reconstruction.html#sec:image-reconstruction">8.8</a>, was described in a paper by Ernst et
al. (<a href="#cite:Ernst2006">2006</a>). This technique is also proposed in Shirley&rsquo;s
Ph.D. thesis (<a href="#cite:Shirley90phd">1990</a>).

</p>
<p>The idea of storing additional information about the properties of the
visible surface in a pixel was introduced by Perlin (<a href="#cite:Perlin85">1985a</a>)
and Saito and Takahashi (<a href="#cite:Saito90">1990</a>), who also coined the term
<em>G-Buffer</em>.  Shade et al. (<a href="#cite:Shade98">1998</a>) introduced the
generalization of storing information about all the surfaces along each
camera ray and applied this representation to view interpolation, using the
originally hidden surfaces to handle disocclusion.

</p>
<p>Celarek et al. (<a href="#cite:Celarek2019">2019</a>) developed techniques for evaluating
sampling schemes based on computing both the expectation and variance of
MSE and described approaches for evaluating error in rendered images across
both pixels and frequencies.

</p>
<p>The sampling technique that approximates the XYZ matching curves is due to
Radziszewski et&nbsp;al. (<a href="#cite:Radziszewski2009">2009</a>).

</p>
<p>The <a href="../Cameras_and_Film/Film_and_Imaging.html#SpectralFilm"><tt>SpectralFilm</tt></a> uses a representation for spectral images in the
OpenEXR format that was introduced by Fichet et
al. (<a href="#cite:Fichet2021">2021</a>).

</p>
<p>As discussed in Section&nbsp;<a href="../Cameras_and_Film/Film_and_Imaging.html#sec:white-balance">5.4.2</a>, the human visual system
generally factors out the illumination color to perceive surfaces&rsquo; colors
independently of it.  A number of
methods have been developed to process photographs to perform white
balancing to eliminate the tinge of light source colors; see Gijsenij
et&nbsp;al. (<a href="#cite:Gijsenij2011">2011</a>) for a survey.  White balancing photographs
can be challenging, since the only information available to white balancing
algorithms is the final pixel values.  In a renderer, the problem is
easier, as information about the light sources is directly available;
Wilkie and Weidlich (<a href="#cite:Wilkie2009">2009</a>) developed an efficient method
to perform accurate white balancing in a renderer.

</p>
<p>

</p>
<p></p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#x7-Denoising"><i class="fas fa-link h3h4marginlink"></i></a>
</div>
<div class="col-md-10 col-lg-8">
<span id="x7-Denoising"></span><h4>Denoising</h4><p>


</p>
<p>A wide range of approaches have been developed for removing Monte Carlo noise from
rendered images.  Here we will discuss those that are based on
the statistical characteristics of the sample values themselves.  In the
&ldquo;Further Reading&rdquo; section of Chapter&nbsp;<a href="../Sampling_and_Reconstruction.html#chap:sampling-reconstruction">8</a>,
we will discuss ones that derive filters that account for the underlying
light transport equations used to form the image.  Zwicker et&nbsp;al.&rsquo;s report
(<a href="#cite:Zwicker15">2015</a>) has thorough coverage of both approaches to
denoising through 2015.  We will therefore focus here on some of the
foundational work as well as more recent developments.

</p>
<p>Lee and Redner (<a href="#cite:Lee90">1990</a>) suggested using an alpha-trimmed mean
filter for this task; it discards some number of samples at the low and
high range of the sample values.  The median filter, where all but a single
sample are discarded, is a special case of it.  Jensen and Christensen
(<a href="#cite:Jensen95noise">1995</a>) observed that it can be effective to
separate out the contributions to pixel values based on the type of
illumination they represent; low-frequency indirect illumination can be
filtered differently from high-frequency direct illumination, thus reducing
noise in the final image.  They developed an effective filtering technique
based on this observation.  

</p>
<p>McCool (<a href="#cite:McCool1999">1999</a>) used the depth, surface normal, and color at
each pixel to determine how to blend pixel values with their neighbors in
order to better preserve edges in the filtered image.  Keller and
collaborators introduced the <em>discontinuity buffer</em>
(Keller&nbsp;<a href="#cite:Keller98">1998</a>; Wald et&nbsp;al.&nbsp;<a href="#cite:Wald02">2002</a>).  In addition
to filtering slowly varying quantities like indirect illumination
separately from more quickly varying quantities like surface reflectance,
the discontinuity buffer also uses geometric quantities like the surface
normal to determine filter extents.

</p>
<p>Dammertz et al. (<a href="#cite:Dammertz2010">2010</a>) introduced a denoising algorithm
based on edge-aware image filtering, applied hierarchically so that very
wide kernels can be used with good performance.  This approach was improved
by Schied et&nbsp;al. (<a href="#cite:Schied2017">2017</a>), who used estimates of variance at
each pixel to set filter widths and incorporated temporal reuse,
using filtered results from the previous frame in a real-time ray
tracer.
Bitterli et&nbsp;al. (<a href="#cite:Bitterli2016">2016</a>) analyzed a variety of previous
denoising techniques in a unified framework and derived a new approach based
on a first-order regression of pixel values.  Boughida and Boubekeur
(<a href="#cite:Boughida2017">2017</a>) described a Bayesian approach based on statistics
of all the samples in a pixel, and Vicini et al. (<a href="#cite:Vicini2019">2019a</a>)
considered the problem of denoising &ldquo;deep&rdquo; images, where each pixel may
contain multiple color values, each at a different depth.

</p>
<p>Some filtering techniques focus solely on the outlier pixels that result
when the sampling probability in the Monte Carlo estimator is a poor
match to the integrand and is far too small for a sample.  (As mentioned
previously, the resulting pixels are sometimes called &ldquo;fireflies,&rdquo; in a
nod to their bright transience.)  Rushmeier and Ward
(<a href="#cite:Rushmeier1994">1994</a>) developed an early technique to address this
issue based on detecting outlier pixels and spreading their energy to
nearby pixels in order to maintain an unbiased estimate of the true image.
DeCoro et&nbsp;al. (<a href="#cite:DeCoro2010">2010</a>) suggested storing all pixel sample
values and then rejecting outliers before filtering them to compute final
pixel values.  Zirr et&nbsp;al. (<a href="#cite:Zirr2018">2018</a>) proposed an improved
approach that uses the distribution of sample values at each pixel to
detect and reweight outlier samples.  Notably, their approach does not need
to store all the individual samples, but can be implemented by
partitioning samples into one of a small number of image buffers based on
their magnitude.  More recently, Buisine et&nbsp;al. (<a href="#cite:Buisine2021">2021</a>)
proposed using a median of means filter, which is effective at removing
outliers but has slower convergence than the mean.  They therefore
dynamically select between the mean and median of means depending on the
characteristics of the sample values.

</p>
<p>As with many other areas of image processing and understanding, techniques
based on machine learning have recently been applied to denoising rendered
images.  This work started with Kalantari
et&nbsp;al. (<a href="#cite:Kalantari2015">2015</a>), who used relatively small neural
networks to determine parameters for conventional denoising filters.
Approaches based on deep learning and convolutional neural networks soon
followed with Bako et&nbsp;al. (<a href="#cite:Bako2017">2017</a>), Chaitanya
et&nbsp;al. (<a href="#cite:Chaitanya2017">2017</a>), and Vogels
et&nbsp;al. (<a href="#cite:Vogels2018">2018</a>) developing autoencoders based on the u-net
architecture (<a href="#cite:Ronneberger2015">Ronneberger et al. 2015</a>). Xu et&nbsp;al. (<a href="#cite:Xu2019">2019</a>) applied
adversarial networks to improve the training of such denoisers.
Gharbi et al. (<a href="#cite:Gharbi2019">2019</a>) showed that filtering the individual
samples with a neural network can give much better results than sampling the pixels with the
samples already averaged. Munkberg and Hasselgren (<a href="#cite:Munkberg2020">2020</a>)
described an architecture that reduces the memory and computation required
for this approach.

</p>
<p></p>
<h3>References</h3>
<ol style="list-style: none;">
<li class="bibitem" id="cite:Adams2007">Adams, A., and M.&nbsp;Levoy. 2007.
General linear cameras with finite aperture.
In <em>Rendering Techniques</em> (<em>Proceedings of the 2007 Eurographics
Symposium on Rendering</em>), 121&ndash;26.
</li>

<li class="bibitem" id="cite:Moller18">Akenine-M&ouml;ller, T., E.&nbsp;Haines, N.&nbsp;Hoffman, A.&nbsp;Peesce, M.&nbsp;Iwanicki, and S.&nbsp;Hillaire. 2018.
<em>Real-Time Rendering</em> (4th ed.).
Boca Raton, FL: CRC Press.
</li>

<li class="bibitem" id="cite:Bako2017">Bako, S., T.&nbsp;Vogels, B.&nbsp;McWilliams, M.&nbsp;Meyer, J.&nbsp;Nov&aacute;k, A.&nbsp;Harvill, P.&nbsp;Sen, T.&nbsp;DeRose, and F.&nbsp;Rousselle. 2017.
Kernel-predicting convolutional networks for denoising Monte Carlo renderings.
<em>ACM Transactions on Graphics (Proceedings of
SIGGRAPH)</em>&nbsp;<em>36</em>&thinsp;(4), 97:1&ndash;14.
</li>

<li class="bibitem" id="cite:Bitterli2016">Bitterli, B., F.&nbsp;Rousselle, B.&nbsp;Moon, J.&nbsp;A.&nbsp;Iglesias-Guiti&aacute;n, D.&nbsp;Adler,
K.&nbsp;Mitchell, W.&nbsp;Jarosz, and J.&nbsp;Nov&aacute;k. 2016.
Nonlinearly weighted first-order regression for denoising Monte Carlo renderings.
<em>Computer Graphics Forum</em>&nbsp;<em>35</em>&thinsp;(4), 107&ndash;17.
</li>

<li class="bibitem" id="cite:Boughida2017">Boughida, M., and T.&nbsp;Boubekeur. 2017.
Bayesian collaborative denoising for Monte Carlo rendering.
<em>Computer Graphics Forum</em>&nbsp;<em>36</em>&thinsp;(4), 137&ndash;53.
</li>

<li class="bibitem" id="cite:Buisine2021">Buisine, J., S.&nbsp;Delepoulle, and C.&nbsp;Renaud. 2021.
Firefly removal in Monte Carlo rendering with adaptive Median of meaNs.
<em>Proceedings of the Eurographics Symposium on Rendering</em>, 121&ndash;32.
</li>

<li class="bibitem" id="cite:Celarek2019">Celarek, A., W.&nbsp;Jakob, M.&nbsp;Wimmer, and J.&nbsp;Lehtinen. 2019.
Quantifying the error of light transport algorithms.
<em>Computer Graphics Forum</em> <em>38</em>&thinsp;(4), 111&ndash;21.
</li>

<li class="bibitem" id="cite:Chaitanya2017">Chaitanya, C.&nbsp;R.&nbsp;A., A.&nbsp;S.&nbsp;Kaplanyan, C.&nbsp;Schied, M.&nbsp;Salvi, A.&nbsp;Lefohn, D.&nbsp;Nowrouzezahrai, and T.&nbsp;Aila. 2017.
Interactive reconstruction of Monte Carlo image sequences using a recurrent
denoising autoencoder.
<em>ACM Transactions on Graphics (Proceedings of
SIGGRAPH)</em>&nbsp;<em>36</em>&thinsp;(4), 98:1&ndash;12.
</li>

<li class="bibitem" id="cite:Chen2009">Chen, J., K.&nbsp;Venkataraman, D.&nbsp;Bakin, B.&nbsp;Rodricks, R.&nbsp;Gravelle, P.&nbsp;Rao, and Y.&nbsp;Ni. 2009.
Digital camera imaging system simulation.
<em>IEEE Transactions on Electron Devices</em>&nbsp;<em>56</em>&thinsp;(11), 2496&ndash;505.
</li>

<li class="bibitem" id="cite:Cook86">Cook, R.&nbsp;L. 1986.
Stochastic sampling in computer graphics.
<em>ACM Transactions on Graphics</em>&nbsp;<em>5</em>&thinsp;(1), 51&ndash;72.
</li>

<li class="bibitem" id="cite:Cook84">Cook, R.&nbsp;L., T.&nbsp;Porter, and L.&nbsp;Carpenter. 1984.
Distributed ray tracing.
<em>Computer Graphics (SIGGRAPH &rsquo;84 Proceedings)</em> <em>18</em>,
137&ndash;45.
</li>

<li class="bibitem" id="cite:Dammertz2010">Dammertz, H., D.&nbsp;Sewtz, J.&nbsp;Hanika, and H.&nbsp;P.&nbsp;A.&nbsp;Lensch. 2010.
Edge-avoiding &Agrave;-Trous wavelet transform for fast global illumination
filtering.
<em>Proceedings of High Performance Graphics (HPG &rsquo;10)</em>, 67&ndash;75.
</li>

<li class="bibitem" id="cite:DeCoro2010">DeCoro, C., T.&nbsp;Weyrich, and S.&nbsp;Rusinkiewicz. 2010.
Density-based outlier rejection in Monte Carlo rendering.
<em>Computer Graphics Forum (Proceedings of Pacific
Graphics)</em>&nbsp;<em>29</em>&thinsp;(7), 2119&ndash;25.
</li>

<li class="bibitem" id="cite:Eberly01">Eberly, D.&nbsp;H. 2001.
<em>3D Game Engine Design: A Practical Approach to Real-Time
  Computer Graphics</em>.
San Francisco: Morgan Kaufmann.
</li>

<li class="bibitem" id="cite:Ernst2006">Ernst, M., M.&nbsp;Stamminger, and G.&nbsp;Greiner. 2006.
Filter importance sampling.
<em>IEEE Symposium on Interactive Ray Tracing</em>, 125&ndash;32.
</li>

<li class="bibitem" id="cite:Fichet2021">Fichet, A., R.&nbsp;Pacanowski, and A.&nbsp;Wilkie. 2021.
An OpenEXR layout for spectral images.
<em>Journal of Computer Graphics Techniques</em> <em>10</em>&thinsp;(3), 1&ndash;18.
</li>

<li class="bibitem" id="cite:Gharbi2019">Gharbi, M., T.-M.&nbsp;Li, M.&nbsp;Aittala, J.&nbsp;Lehtinen, and F.&nbsp;Durand. 2019.
Sample-based Monte Carlo denoising using a kernel-splatting network.
<em>ACM Transactions on Graphics (Proceedings of
SIGGRAPH)</em>&nbsp;<em>38</em>&thinsp;(4), 125:1&ndash;12.
</li>

<li class="bibitem" id="cite:Gijsenij2011">Gijsenij, A., T.&nbsp;Gevers, and J. van de Weijer. 2011.
Computational color constancy: Survey and experiments.
<em>IEEE Transactions on Image Processing</em>&nbsp;<em>20</em>&thinsp;(9), 2475&ndash;89.
</li>

<li class="bibitem" id="cite:Glassner1999">Glassner, A. 1999. An open and shut case. <em>IEEE Computer Graphics and
Applications 19</em>&thinsp;(3), 82&ndash;92.
</li>

<li class="bibitem" id="cite:Gortler96">Gortler, S.&nbsp;J., R.&nbsp;Grzeszczuk, R.&nbsp;Szeliski, and M.&nbsp;F. Cohen. 1996.
The lumigraph.
<em>Proceedings of SIGGRAPH &rsquo;96</em>, Computer Graphics Proceedings,
  Annual Conference Series, 43&ndash;54.
</li>

<li class="bibitem" id="cite:Greene86ewa">Greene, N., and P.&nbsp;S. Heckbert. 1986.
Creating raster Omnimax images from multiple perspective views using
  the elliptical weighted average filter.
<em>IEEE Computer Graphics and Applications</em>&nbsp;<em>6</em>&thinsp;(6), 21&ndash;27.
</li>

<li class="bibitem" id="cite:Gribel2017">Gribel, C.&nbsp;J., and T.&nbsp;Akenine-M&ouml;ller. 2017.
Time-continuous quasi-Monte Carlo ray tracing.
<em>Computer Graphics Forum</em>&nbsp;<em>36</em>&thinsp;(6), 354&ndash;67.
</li>

<li class="bibitem" id="cite:Hanika2014">Hanika, J., and C.&nbsp;Dachsbacher.  2014.
Efficient Monte Carlo rendering with realistic lenses.
<em>Computer Graphics Forum (Proceedings of Eurographics 2014)</em>&nbsp;<em>33</em>&thinsp;(2), 323&ndash;32.
</li>

<li class="bibitem" id="cite:Hasinoff2011">Hasinoff, S.&nbsp;W., and K.&nbsp;N. Kutulakos. 2011.
Light-efficient photography. 
<em>IEEE Transactions on Pattern Analysis and Machine
Intelligence</em>&nbsp;<em>33</em>&thinsp;(11), 2203&ndash;14.
</li>

<li class="bibitem" id="cite:Hecht2002">Hecht, E. 2002.
<em>Optics</em>. 
Reading, Massachusetts: Addison-Wesley.
</li>

<li class="bibitem" id="cite:Hullin2012">Hullin, M.&nbsp;B., J.&nbsp;Hanika, and W.&nbsp;Heidrich. 2012.
Polynomial optics: A construction kit for efficient ray-tracing of lens systems.
<em>Computer Graphics Forum (Proceedings of the 2012 Eurographics Symposium on
Rendering)</em>&nbsp;<em>31</em>&thinsp;(4), 1375&ndash;83.
</li>

<li class="bibitem" id="cite:Jacobs2012">Jacobs, D.&nbsp;E., J.&nbsp;Baek, and M.&nbsp;Levoy. 2012.
Focal stack compositing for depth of field control.
<em>Stanford Computer Graphics Laboratory Technical Report</em>, CSTR 2012-1.
</li>

<li class="bibitem" id="cite:Jensen95noise">Jensen, H.&nbsp;W., and N.&nbsp;Christensen. 1995.
Optimizing path tracing using noise reduction filters.
In <em>Proceedings of WSCG</em>,  134&ndash;42.
</li>

<li class="bibitem" id="cite:Joo2016">Joo, H., S.&nbsp;Kwon, S.&nbsp;Lee, E.&nbsp;Eisemann, and S.&nbsp;Lee. 2016.
Efficient ray tracing through aspheric lenses and imperfect Bokeh synthesis.
<em>Computer Graphics Forum</em>&nbsp;<em>35</em>&thinsp;(4), 99&ndash;105.
</li>

<li class="bibitem" id="cite:Kalantari2015">Kalantari, N.&nbsp;K., S.&nbsp;Bako, and P.&nbsp;Sen. 2015.
A machine learning approach for filtering Monte Carlo noise.
<em>ACM Transactions on Graphics (Proceedings of SIGGRAPH
2015)</em>&nbsp;<em>34</em>&thinsp;(4), 122:1&ndash;12.
</li>

<li class="bibitem" id="cite:Keller98">Keller, A.  1998.
Quasi-Monte Carlo methods for photorealistic image synthesis.
Ph.D. thesis, Shaker Verlag Aachen.
</li>

<li class="bibitem" id="cite:Kensler2021">Kensler, A. 2021.
Tilt-shift rendering using a thin lens model.
In Marrs, A., P.&nbsp;Shirley, and I.&nbsp;Wald (eds.), <em>Ray Tracing Gems II</em>,
499&ndash;513. Berkeley: Apress.
</li>

<li class="bibitem" id="cite:Kolb95">Kolb, C.,  D.&nbsp;Mitchell, and P.&nbsp;Hanrahan. 1995.
A realistic camera model for computer graphics.
<em>SIGGRAPH &rsquo;95 Conference Proceedings</em>, Annual
  Conference Series, 317&ndash;24.
</li>

<li class="bibitem" id="cite:Langlands2020">Langlands, A., and L.&nbsp;Fascione. 2020.
PhysLight: An end-to-end pipeline for scene-referred lighting.
<em>SIGGRAPH 2020 Talks</em>&nbsp;<em>19</em>, 191&ndash;2.
</li>

<li class="bibitem" id="cite:Lee90">Lee, M., and R. Redner. 1990.
A note on the use of nonlinear filtering in computer graphics.
<em>IEEE Computer Graphics and Applications</em>&nbsp;<em>10</em>&thinsp;(3),  23&ndash;29.
</li>

<li class="bibitem" id="cite:Levoy96">Levoy, M., and P.&nbsp;M. Hanrahan. 1996.
Light field rendering.
In <em>Proceedings of SIGGRAPH &rsquo;96</em>, Computer Graphics Proceedings,
  Annual Conference Series, 31&ndash;42.
</li>

<li class="bibitem" id="cite:McCool1999">McCool, M.&nbsp;D. 1999.
Anisotropic diffusion for Monte Carlo noise reduction.
<em>ACM Transactions on Graphics</em>&nbsp;<em>18</em>&thinsp;(2), 171&ndash;94.
</li>

<li class="bibitem" id="cite:Munkberg2020">Munkberg, J., and J.&nbsp;Hasselgren. 2020.
Neural denoising with layer embeddings.
<em>Computer Graphics Forum</em>&nbsp;<em>39</em>&thinsp;(4), 1&ndash;12.
</li>

<li class="bibitem" id="cite:Ng2005">Ng, R., M.&nbsp;Levoy, M.&nbsp;Br&eacute;dif., G.&nbsp;Duval, M.&nbsp;Horowitz, and P.&nbsp;Hanrahan. 2005.
Light field photography with a hand-held plenoptic camera.
<em>Stanford University Computer Science Technical Report</em>, CSTR 2005-02.
</li>

<li class="bibitem" id="cite:Perlin85">Perlin, K. 1985a.
An image synthesizer.
In <em>Computer Graphics (SIGGRAPH &rsquo;85 Proceedings)</em>, Volume&nbsp;19,
  287&ndash;96.
</li>

<li class="bibitem" id="cite:Potmesil81">Potmesil, M., and I.&nbsp;Chakravarty. 1981.
A lens and aperture camera model for synthetic image generation.
In <em>Computer Graphics (Proceedings of SIGGRAPH &rsquo;81)</em>, Volume&nbsp;15,
297&ndash;305.
</li>

<li class="bibitem" id="cite:Potmesil82">Potmesil, M., and I.&nbsp;Chakravarty. 1982.
Synthetic image generation with a lens and aperture camera model.
<em>ACM Transactions on Graphics</em>&nbsp;<em>1</em>&thinsp;(2), 85&ndash;108.
</li>

<li class="bibitem" id="cite:Potmesil83">Potmesil, M., and I.&nbsp;Chakravarty. 1983.
Modeling motion blur in computer-generated images.
In <em>Computer Graphics (Proceedings of SIGGRAPH 83)</em>, Volume&nbsp;17, 389&ndash;99.
</li>

<li class="bibitem" id="cite:Radziszewski2009">Radziszewski, M., K.&nbsp;Boryczko, and W.&nbsp;Alda. 2009.
An improved technique for full spectral rendering. 
<em>Journal of WSCG</em>&nbsp;<em>17</em>&thinsp;(1-3), 9&ndash;16.
</li>

<li class="bibitem" id="cite:Rogers90">Rogers, D.&nbsp;F., and J.&nbsp;A. Adams. 1990.
<em>Mathematical Elements for Computer Graphics</em>.
New York: McGraw-Hill.
</li>

<li class="bibitem" id="cite:Ronneberger2015">Ronneberger, O., P.&nbsp;Fischer, and T.&nbsp;Brox. 2015.
U-Net: Convolutional networks for biomedical image segmentation.
<em>Medical Image Computing and Computer-Assisted
Intervention</em>&nbsp;<em>9351</em>, 234&ndash;41.
</li>

<li class="bibitem" id="cite:Rushmeier1994">Rushmeier, H.&nbsp;E., and G.&nbsp;J. Ward. 1994.
Energy preserving non-linear filters.
<em>Proceedings of SIGGRAPH 1994</em>, 131&ndash;38.
</li>

<li class="bibitem" id="cite:Saito90">Saito, T., and T.&nbsp;Takahashi. 1990.
Comprehensible rendering of 3-D shapes.
In <em>Computer Graphics (Proceedings of SIGGRAPH &rsquo;90)</em>, Volume&nbsp;24,
  197&ndash;206.
</li>

<li class="bibitem" id="cite:Schied2017">Schied, S., A.&nbsp;Kaplanyan, C.&nbsp;Wyman, A.&nbsp;Patney, C.&nbsp;R.&nbsp;Alla Chaitanya,
J.&nbsp;Burgess, S.&nbsp;Liu, C.&nbsp;Dachsbacher, A.&nbsp;Lefohn, and M.&nbsp;Salvi. 2017.
Spatiotemporal variance-guided filtering: Real-time reconstruction for
path-traced global illumination.
In <em>Proceedings of High Performance Graphics (HPG &rsquo;17)</em>, 2:1&ndash;12.
</li>

<li class="bibitem" id="cite:Schrade2016">Schrade, E., J.&nbsp;Hanika, and C.&nbsp;Dachsbacher. 2016.
Sparse high-degree polynomials for wide-angle lenses.
<em>Computer Graphics Forum</em>&nbsp;<em>35</em>&thinsp;(4), 89&ndash;97.
</li>

<li class="bibitem" id="cite:Shade98">Shade, J., S.&nbsp;J.&nbsp;Gortler, L.&nbsp;W.&nbsp;He, and R.&nbsp;Szeliski. 1998.
Layered depth images.
In <em>Proceedings of SIGGRAPH 98</em>, Computer Graphics Proceedings,
  Annual Conference Series, 231&ndash;42.
</li>

<li class="bibitem" id="cite:Shirley90phd">Shirley, P. 1990.
Physically based lighting calculations for computer graphics.
Ph.D. thesis, Department of Computer Science, University of Illinois,
  Urbana&ndash;Champaign.
</li>

<li class="bibitem" id="cite:Smith2007">Smith, W. 2007.
<em>Modern Optical Engineering</em> (4th ed.).
New York: McGraw-Hill Professional.
</li>

<li class="bibitem" id="cite:Steinert2011">Steinert, B., H.&nbsp;Dammertz., J.&nbsp;Hanika, and H.&nbsp;P.&nbsp;A.&nbsp;Lensch.
General spectral camera lens simulation. 2011.
<em>Computer Graphics Forum</em>&nbsp;<em>30</em>&thinsp;(6),
1643&ndash;54.
</li>

<li class="bibitem" id="cite:Stephenson07">Stephenson, I. 2007.
Improving motion blur: Shutter efficiency and temporal sampling.
<em>Journal of Graphics Tools</em>&nbsp;<em>12</em>&thinsp;(1), 9&ndash;15.
</li>

<li class="bibitem" id="cite:Sutherland63">Sutherland, I.&nbsp;E. 1963.
Sketchpad&mdash;A man&ndash;machine graphical communication system.
In <em>Proceedings of the Spring Joint Computer Conference (AFIPS)</em>,
  328&ndash;46.
</li>

<li class="bibitem" id="cite:Vicini2019">Vicini, D., D.&nbsp;Adler, J.&nbsp;Nov&aacute;k, F.&nbsp;Rousselle, and B.&nbsp;Burley. 2019a.
Denoising deep Monte Carlo renderings.
<em>Computer Graphics Forum</em>&nbsp;<em>38</em>&thinsp;(1).
</li>

<li class="bibitem" id="cite:Vogels2018">Vogels, T., F.&nbsp;Rousselle, B.&nbsp;McWilliams, G.&nbsp;R&ouml;thlin, A.&nbsp;Harvill, D.&nbsp;Adler, M.&nbsp;Meyer, and J.&nbsp;Nov&aacute;k. 2018.
Denoising with kernel prediction and asymmetric loss functions.
<em>ACM Transactions on Graphics (Proceedings of
SIGGRAPH)</em>&nbsp;<em>37</em>&thinsp;(4), 124:1&ndash;15.
</li>

<li class="bibitem" id="cite:Wald02">Wald, I., T.&nbsp;Kollig, C.&nbsp;Benthin, A.&nbsp;Keller, and P.&nbsp;Slusallek. 2002.
Interactive global illumination using fast ray tracing.
In <em>Rendering Techniques 2002: 13th Eurographics Workshop on
  Rendering</em>, 15&ndash;24.
</li>

<li class="bibitem" id="cite:Wilkie2009">Wilkie, A., and A.&nbsp;Weidlich. 2009.
A robust illumination estimate for chromatic adaptation in rendered images.
<em>Computer Graphics Forum (Proceedings of the 2009 Eurographics
Symposium on Rendering)</em>&nbsp;<em>28</em>&thinsp;(4), 1101&ndash;9.
</li>

<li class="bibitem" id="cite:Xu2019">Xu, B., J.&nbsp;Zhang, R.&nbsp;Wang, K.&nbsp;Xu, Y.-L.&nbsp;Yang, C.&nbsp;Li, and R.&nbsp;Tang. 2019.
Adversarial Monte Carlo denoising with conditioned auxiliary feature.
<em>ACM Transactions on Graphics (Proceedings of SIGGRAPH
Asia)</em>&nbsp;<em>38</em>&thinsp;(6), 224:1&ndash;12.
</li>

<li class="bibitem" id="cite:Zirr2018">Zirr, T., J.&nbsp;Hanika, and C.&nbsp;Dachsbacher. 2018.
Reweighting firefly samples for improved finite-sample Monte Carlo estimates.
<em>Computer Graphics Forum</em>&nbsp;<em>37</em>&thinsp;(6), 410&ndash;21.
</li>

<li class="bibitem" id="cite:Zwicker15">Zwicker, M., W.&nbsp;Jarosz, J.&nbsp;Lehtinen, B.&nbsp;Moon, R.&nbsp;Ramamoorthi,
F.&nbsp;Rousselle, P.&nbsp;Sen, C.&nbsp;Soler, and S.-E.&nbsp;Yoon. 2015.
Recent advances in adaptive sampling and reconstruction for Monte Carlo rendering.
<em>Computer Graphics Forum (Proceedings of Eurographics 2015)</em>&nbsp;<em>34</em>&thinsp;(2), 667&ndash;81.
</li>

</ol>
<p>


</p>
<p>

</p>
<p></p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

</div>  <!-- container-fluid -->
</div>  <!-- maincontainer -->

<nav class="navbar navbar-expand-md bg-light navbar-light">
<div class="container-fluid">
  <span class="navbar-text"><i>Physically Based Rendering: From Theory To Implementation</i>,<br>
<a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">&copy; 2004-2023</a> Matt Pharr, Wenzel Jakob, and Greg Humphreys.
<a href="https://github.com/mmp/pbr-book-website/"><span class="fab fa-github"></span></a><br>
Purchase a printed copy: <a href="https://www.amazon.com/Physically-Based-Rendering-fourth-Implementation/dp/0262048027?keywords=physically+based+rendering+4th+edition&qid=1671730412&sprefix=physically+based%!C(MISSING)aps%!C(MISSING)145&sr=8-1&linkCode=ll1&tag=pharr-20&linkId=81a816d90f0c7e872617f1f930a51fd6&language=en_US&ref_=as_li_ss_tl"><span class="fab fa-amazon"></span></a>
<a href="https://mitpress.mit.edu/9780262048026/physically-based-rendering/"><img src="/mitpress.png" width=10 height=16></a>
</span>
</div>
  <div class="container">
    <ul class="nav navbar-nav ml-auto">
      <li class="nav-item">Next: <a href="../Cameras_and_Film/Exercises.html">Cameras and Film / Exercises</a></li>
    </ul>
  </div>

</nav>

<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script>
  $(function () {
    $('[data-toggle="popover"]').popover()
    $('[data-toggle="tooltip"]').tooltip()
   })
</script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

<script>
// https://stackoverflow.com/a/17535094
// The function actually applying the offset
function offsetAnchor() {
  if (location.hash.length !== 0) {
    window.scrollTo(window.scrollX, window.scrollY - window.innerHeight / 8);
  }
}

// Captures click events of all <a> elements with href starting with #
$(document).on('click', 'a[href^="#"]', function(event) {
  // Click events are captured before hashchanges. Timeout
  // causes offsetAnchor to be called after the page jump.
  window.setTimeout(function() {
    offsetAnchor();
  }, 500);
});

// Set the offset when entering page with hash present in the url
window.setTimeout(offsetAnchor, 1500);
</script>

</body>
</html>
